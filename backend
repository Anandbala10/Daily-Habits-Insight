# -----------------------------------------
# üìä Enhanced Daily Habits Tracker Analysis (Refactored)
# Goal: Advanced analysis, predictive modeling, and insights
#       with a focus on code quality, modularity, and reusability.
# -----------------------------------------

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
import warnings
import os

warnings.filterwarnings('ignore')
plt.style.use('seaborn-v0_8')


# --- Helper Functions ---
def print_header(title):
    """Prints a formatted header to the console."""
    print("\n" + "=" * 60)
    print(f"üìä {title.upper()}")
    print("=" * 60)


# --- Core Logic Functions ---

def load_and_preprocess_data(filepath="habits_60_days.csv"):
    """
    Loads the dataset from a CSV file, adds time-based and engineered features.
    Returns a pandas DataFrame.
    """
    print_header("Step 1: Data Loading & Preprocessing")
    try:
        df = pd.read_csv(filepath)
        print(f"‚úÖ Dataset loaded successfully! Shape: {df.shape}")
    except FileNotFoundError:
        print(f"‚ùå Error: '{filepath}' not found. Please ensure the file is in the correct directory.")
        return None

    # Convert date and add time-based features
    df["Date"] = pd.to_datetime(df["Date"])
    df['DayOfWeek'] = df['Date'].dt.day_name()
    df['WeekNumber'] = df['Date'].dt.isocalendar().week
    df['IsWeekend'] = df['Date'].dt.weekday >= 5

    # Create enhanced features
    df["ProductivityScore"] = (df["StudyHours"] + (df["Exercise(mins)"] / 60)) - df["ScreenTime(hrs)"]
    df["SleepQuality"] = np.where(df["SleepHours"] >= 7, "Good", "Poor")

    print(f"--- Date Range: {df['Date'].min().date()} to {df['Date'].max().date()} ---")
    return df


def run_statistical_analysis(df):
    """
    Performs correlation and comparative statistical analysis.
    Prints the results to the console.
    """
    print_header("Step 2: Statistical Analysis")

    # Key correlations with statistical significance
    key_correlations = [
        ("SleepHours", "Mood(1-5)"),
        ("StudyHours", "Mood(1-5)"),
        ("ScreenTime(hrs)", "SleepHours"),
        ("Exercise(mins)", "Mood(1-5)"),
        ("ProductivityScore", "Mood(1-5)")
    ]

    print("\nüîç Key Correlations with Statistical Significance:")
    print("-" * 55)
    for col1, col2 in key_correlations:
        corr_coef, p_value = stats.pearsonr(df[col1], df[col2])
        significance = "***" if p_value < 0.001 else "**" if p_value < 0.01 else "*" if p_value < 0.05 else ""
        print(f"{col1:17} ‚Üî {col2:17}: {corr_coef:6.3f} {significance:3} (p={p_value:.4f})")
    print("\nSignificance levels: *** p<0.001, ** p<0.01, * p<0.05")

    # Weekend vs Weekday comparison T-test
    mood_weekday = df[~df['IsWeekend']]['Mood(1-5)']
    mood_weekend = df[df['IsWeekend']]['Mood(1-5)']
    t_stat, p_val = stats.ttest_ind(mood_weekday, mood_weekend)

    print(f"\nüìä Weekend vs Weekday Mood Difference:")
    print(
        f"   T-statistic: {t_stat:.3f}, P-value: {p_val:.4f} -> {'Significant difference' if p_val < 0.05 else 'No significant difference'}")


def create_and_save_visualizations(df, output_dir="visualizations"):
    """
    Generates and saves key visualizations to the specified directory.
    """
    print_header("Step 3: Creating and Saving Visualizations")
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"üìÇ Created directory: '{output_dir}'")

    # 1. Enhanced Correlation Heatmap
    fig, axes = plt.subplots(2, 2, figsize=(20, 16))
    fig.suptitle('Habit Analysis Dashboard', fontsize=20, weight='bold')

    corr_matrix = df[
        ['SleepHours', 'StudyHours', 'ScreenTime(hrs)', 'Exercise(mins)', 'Mood(1-5)', 'ProductivityScore']].corr()
    sns.heatmap(corr_matrix, annot=True, cmap="RdBu_r", center=0, fmt='.2f', ax=axes[0, 0], linewidths=.5)
    axes[0, 0].set_title("Correlation Matrix of Habits and Mood", weight='bold')

    # 2. Mood Distribution by Sleep Quality
    sns.boxplot(x='SleepQuality', y='Mood(1-5)', data=df, ax=axes[0, 1], palette="pastel")
    axes[0, 1].set_title("Mood Distribution by Sleep Quality", weight='bold')
    axes[0, 1].set_xlabel("Sleep Quality (7+ hours = Good)")

    # 3. Weekly Mood Patterns Heatmap
    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    weekly_pivot = df.pivot_table(values='Mood(1-5)', index='DayOfWeek', columns='WeekNumber', aggfunc='mean').reindex(
        day_order)
    sns.heatmap(weekly_pivot, cmap="viridis", cbar_kws={'label': 'Average Mood (1-5)'}, ax=axes[1, 0], linewidths=.5)
    axes[1, 0].set_title("Weekly Mood Heatmap", weight='bold')

    # 4. Mood Trend with Moving Average
    df_sorted = df.sort_values('Date')
    df_sorted['Mood_7day_avg'] = df_sorted['Mood(1-5)'].rolling(window=7, center=True).mean()
    axes[1, 1].plot(df_sorted['Date'], df_sorted['Mood(1-5)'], alpha=0.4, label='Daily Mood', marker='o',
                    linestyle='None')
    axes[1, 1].plot(df_sorted['Date'], df_sorted['Mood_7day_avg'], linewidth=2.5, label='7-day Moving Average',
                    color='navy')
    axes[1, 1].set_title("Mood Trend Over Time", weight='bold')
    axes[1, 1].legend()
    axes[1, 1].tick_params(axis='x', rotation=45)

    plt.tight_layout(rect=[0, 0, 1, 0.96])
    save_path = os.path.join(output_dir, "habit_analysis_dashboard.png")
    plt.savefig(save_path, dpi=150)
    print(f"‚úÖ Visualizations saved to '{save_path}'")
    plt.show()
    plt.close()


def train_and_evaluate_models(df):
    """
    Prepares data, trains Linear Regression and RandomForest models,
    and returns the trained models and their performance metrics.
    """
    print_header("Step 4: Predictive Modeling")

    # Prepare features and target
    feature_cols = ['SleepHours', 'StudyHours', 'ScreenTime(hrs)', 'Exercise(mins)']
    X = df[feature_cols]
    y = df['Mood(1-5)']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Scale features - Best Practice
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # --- Models ---
    models = {
        "Linear Regression": LinearRegression(),
        "Random Forest": RandomForestRegressor(n_estimators=100, random_state=42)
    }

    results = {}

    print("\nüéØ Model Performance Comparison:")
    print("-" * 40)

    for name, model in models.items():
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)
        r2 = r2_score(y_test, y_pred)
        mse = mean_squared_error(y_test, y_pred)
        results[name] = {'model': model, 'r2': r2, 'mse': mse, 'scaler': scaler, 'features': feature_cols}
        print(f"{name:<20} R¬≤ = {r2:.3f}, MSE = {mse:.3f}")

    return results


def generate_actionable_insights(df, model_results):
    """
    Generates and prints personalized habit recommendations based on
    statistical analysis and model feature importances.
    """
    print_header("Step 5: Actionable Insights & Recommendations")

    # Optimal ranges from top quartile mood days
    high_mood_days = df[df['Mood(1-5)'] >= df['Mood(1-5)'].quantile(0.75)]
    print("\nüéØ Optimal Habit Ranges (based on your best days):")
    print("-" * 55)
    for col in ['SleepHours', 'StudyHours', 'ScreenTime(hrs)', 'Exercise(mins)']:
        optimal_mean = high_mood_days[col].mean()
        current_mean = df[col].mean()
        print(f"{col:17}: Optimal = {optimal_mean:5.1f} | Your Avg = {current_mean:5.1f}")

    # Feature Importance from the best model (Random Forest in this case often gives good insights)
    rf_results = model_results["Random Forest"]
    feature_importance = pd.DataFrame({
        'Feature': rf_results['features'],
        'Importance': rf_results['model'].feature_importances_
    }).sort_values('Importance', ascending=False)

    print("\nüîç Most Impactful Habits (from Random Forest):")
    print("-" * 40)
    print(feature_importance.to_string(index=False))

    # Specific Recommendations
    print("\nüí° SPECIFIC RECOMMENDATIONS:")
    top_habit = feature_importance.iloc[0]['Feature']
    print(f"   1. Your mood is most sensitive to '{top_habit}'. Prioritize improving this habit.")

    optimal_sleep = high_mood_days['SleepHours'].mean()
    print(f"   2. Aim for around {optimal_sleep:.1f} hours of sleep, as this is the average on your best days.")

    avg_exercise_on_best_days = high_mood_days['Exercise(mins)'].mean()
    print(f"   3. Try to get at least {avg_exercise_on_best_days:.0f} minutes of exercise daily.")

    print("\n" + "=" * 60)
    print("Analysis Complete! üéâ")
    print("=" * 60)


# --- Main Execution Block ---
def main():
    """
    Main function to execute the entire data analysis pipeline.
    """
    # Define the data source
    csv_filepath = "habits_60_days.csv"

    # Run the pipeline
    df = load_and_preprocess_data(csv_filepath)

    if df is not None:
        run_statistical_analysis(df)
        create_and_save_visualizations(df)
        model_results = train_and_evaluate_models(df)
        generate_actionable_insights(df, model_results)


if __name__ == "__main__":
    main()
